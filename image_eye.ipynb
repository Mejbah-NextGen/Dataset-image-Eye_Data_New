{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67932252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import Adam, Adamax\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53add197",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r'G:\\Dataset-image-Eye_Data_New'\n",
    "path_list=os.listdir(path)\n",
    "classes=[]\n",
    "file_Paths=[]\n",
    "labels=[]\n",
    "\n",
    "for i in path_list:\n",
    "    class_path=os.path.join(path,i)\n",
    "    if os.path.isdir(class_path):\n",
    "        if i !=\".git\":\n",
    "            classes.append(i)\n",
    "class_count=len(classes)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51186897",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in classes:\n",
    "    class_path=os.path.join(path,j)\n",
    "    image_names=os.listdir(class_path)\n",
    "    for k in image_names:\n",
    "        image_path=os.path.join(class_path,k)\n",
    "        file_Paths.append(image_path)\n",
    "        labels.append(j)\n",
    "file_Paths[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb89e0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_series=pd.Series(file_Paths,name='file_path')\n",
    "label_series=pd.Series(labels,name='label')\n",
    "data_df=pd.concat([file_series,label_series],axis=1)\n",
    "print(data_df.head(10))\n",
    "balance_df=data_df['label'].value_counts()\n",
    "balance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa6adaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split=.8\n",
    "test_split=.1\n",
    "dummy_split=test_split/(1-train_split)\n",
    "train_df,dummy_df=train_test_split(data_df,train_size=train_split,shuffle=True,random_state=125)\n",
    "test_df,valid_df=train_test_split(dummy_df,train_size=dummy_split,shuffle=True,random_state=125)\n",
    "batch_size=16\n",
    "length=len(test_df)\n",
    "print(f\"Train Size: {len(train_df)}\\nTest size: {len(test_df)}\\nValid size: {len(valid_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36def8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalar(x):\n",
    "    return x/127.5-1\n",
    "trgen=tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=scalar, horizontal_flip=True)\n",
    "train_gen=trgen.flow_from_dataframe(train_df, x_col='file_path', y_col='label', target_size=(448,448), class_mode='categorical',batch_size=batch_size, shuffle=True, seed=123)\n",
    "tvgen=tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=scalar)\n",
    "valid_gen=tvgen.flow_from_dataframe(valid_df, x_col='file_path', y_col='label', target_size=(448,448), class_mode='categorical',\n",
    "                                   batch_size=batch_size, shuffle=False)\n",
    "test_batch_size=sorted([int(length/n) for n in range(1,length+1) if length % n ==0 and length/n<=batch_size],reverse=True)[0]\n",
    "test_steps=int(length/test_batch_size)\n",
    "test_gen=tvgen.flow_from_dataframe(test_df, x_col='file_path', y_col='label', target_size=(448,448), class_mode='categorical',\n",
    "                                   batch_size=test_batch_size, shuffle=False)\n",
    "test_labels=test_gen.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab41ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_training_samples(gen):\n",
    "    class_dict=gen.class_indices\n",
    "    new_dict={}\n",
    "    for key, value in class_dict.items(): \n",
    "        new_dict[value]=key\n",
    "    images,labels=next(gen) \n",
    "    plt.figure(figsize=(15, 15))\n",
    "    length=len(labels)\n",
    "    if length<25: \n",
    "        r=length\n",
    "    else:\n",
    "        r=25\n",
    "    for i in range(r):\n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        image=(images[i]+1 )/2 \n",
    "        plt.imshow(image)\n",
    "        index=np.argmax(labels[i])\n",
    "        class_name=new_dict[index]\n",
    "        plt.title(class_name, color='blue', fontsize=16)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a358f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape=(448,448,3)\n",
    "neurons=512\n",
    "dropout=.3\n",
    "lr=.001\n",
    "freeze=True\n",
    "base_model=tf.keras.applications.VGG19(include_top=False, input_shape=img_shape, pooling='max', weights='imagenet')\n",
    "if freeze:\n",
    "    base_model.trainable=False\n",
    "x=base_model.output\n",
    "x=tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\n",
    "x =tf.keras.layers.Dense(neurons, kernel_regularizer = regularizers.l2(0.016),activity_regularizer=regularizers.l1(0.006),\n",
    "                bias_regularizer=regularizers.l1(0.006) ,activation='relu', kernel_initializer= tf.keras.initializers.GlorotUniform(seed=123))(x)\n",
    "x=tf.keras.layers.Dropout(rate=dropout, seed=123)(x)\n",
    "output=tf.keras.layers.Dense(class_count, activation='softmax',kernel_initializer=tf.keras.initializers.GlorotUniform(seed=123))(x)\n",
    "model=Model(inputs=base_model.input, outputs=output)\n",
    "model.compile(Adamax(learning_rate=lr), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f018d766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_in_color(txt_msg,fore_tupple,back_tupple,):\n",
    "    rf,gf,bf=fore_tupple\n",
    "    rb,gb,bb=back_tupple\n",
    "    msg='{0}' + txt_msg\n",
    "    mat='\\33[38;2;' + str(rf) +';' + str(gf) + ';' + str(bf) + ';48;2;' + str(rb) + ';' +str(gb) + ';' + str(bb) +'m'\n",
    "    print(msg .format(mat), flush=True)\n",
    "    print('\\33[0m', flush=True)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922a9f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRA(keras.callbacks.Callback):\n",
    "    def __init__(self, patience, stop_patience, threshold, factor, dwell, model_name, freeze, end_epoch):\n",
    "        super(LRA, self).__init__()\n",
    "        self.patience = patience\n",
    "        self.stop_patience = stop_patience\n",
    "        self.threshold = threshold\n",
    "        self.factor = factor\n",
    "        self.dwell = dwell\n",
    "        self.lr = 0\n",
    "        self.highest_tracc = 0.0\n",
    "        self.lowest_vloss = np.inf\n",
    "        self.count = 0\n",
    "        self.stop_count = 0\n",
    "        self.end_epoch = end_epoch\n",
    "        self.best_weights = None\n",
    "        msg = ' '\n",
    "        if freeze:\n",
    "            msgs = f' Starting training using base model {model_name} with weights frozen to imagenet weights initializing LRA callback'\n",
    "        else:\n",
    "            msgs = f' Starting training using base model {model_name} training all layers '\n",
    "        print_in_color(msgs, (244, 252, 3), (55, 65, 80))\n",
    "\n",
    "    def set_model(self, model):\n",
    "        self.model_ = model\n",
    "        self.lr = float(tf.keras.backend.get_value(model.optimizer.learning_rate))\n",
    "        self.best_weights = self.model_.get_weights()\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        if epoch != 0:\n",
    "            msgs = f'for epoch {epoch} '\n",
    "            msgs = msgs + LRA.msg\n",
    "            print_in_color(msgs, (255, 255, 0), (55, 65, 80))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        lr = float(tf.keras.backend.get_value(self.model_.optimizer.learning_rate))\n",
    "        v_loss = logs.get('val_loss')\n",
    "        acc = logs.get('accuracy')\n",
    "\n",
    "        if acc < self.threshold:\n",
    "            if acc > self.highest_tracc:\n",
    "                LRA.msg = f' training accuracy improved from  {self.highest_tracc:7.4f} to {acc:7.4f} learning rate held at {lr:10.8f}'\n",
    "                self.highest_tracc = acc\n",
    "                LRA.best_weights = self.model_.get_weights()\n",
    "                self.count = 0\n",
    "                self.stop_count = 0\n",
    "                if v_loss < self.lowest_vloss:\n",
    "                    self.lowest_vloss = v_loss\n",
    "            else:\n",
    "                if self.count >= self.patience - 1:\n",
    "                    self.lr = lr * self.factor\n",
    "                    self.model_.optimizer.learning_rate.assign(self.lr)\n",
    "                    self.count = 0\n",
    "                    self.stop_count = self.stop_count + 1\n",
    "                    if self.dwell:\n",
    "                        self.model_.set_weights(LRA.best_weights)\n",
    "                    else:\n",
    "                        if v_loss < self.lowest_vloss:\n",
    "                            self.lowest_vloss = v_loss\n",
    "                    msgs = f' training accuracy {acc:7.4f} < highest accuracy of {self.highest_tracc:7.4f} '\n",
    "                    LRA.msg = msgs + f' for {self.patience} epochs, lr adjusted to {self.lr:10.8f}'\n",
    "                else:\n",
    "                    self.count = self.count + 1\n",
    "                    LRA.msg = f' training accuracy {acc:7.4f} < highest accuracy of {self.highest_tracc:7.4f} '\n",
    "        else:\n",
    "            if v_loss < self.lowest_vloss:\n",
    "                msgs = f' validation loss improved from {self.lowest_vloss:8.5f} to {v_loss:8.5}, saving best weights'\n",
    "                LRA.msg = msgs + f' learning rate held at {self.lr:10.8f}'\n",
    "                self.lowest_vloss = v_loss\n",
    "                LRA.best_weights = self.model_.get_weights()\n",
    "                self.count = 0\n",
    "                self.stop_count = 0\n",
    "            else:\n",
    "                if self.count >= self.patience - 1:\n",
    "                    self.lr = self.lr * self.factor\n",
    "                    self.stop_count = self.stop_count + 1\n",
    "                    msgs = f' val_loss of {v_loss:8.5f} > {self.lowest_vloss:8.5f} for {self.patience} epochs'\n",
    "                    LRA.msg = msgs + f', lr adjusted to {self.lr:10.8f}'\n",
    "                    self.count = 0\n",
    "                    self.model_.optimizer.learning_rate.assign(self.lr)\n",
    "                    if self.dwell:\n",
    "                        self.model_.set_weights(LRA.best_weights)\n",
    "                else:\n",
    "                    self.count = self.count + 1\n",
    "                    LRA.msg = f' validation loss of {v_loss:8.5f} > {self.lowest_vloss:8.5f}'\n",
    "                if acc > self.highest_tracc:\n",
    "                    self.highest_tracc = acc\n",
    "\n",
    "        if epoch == self.end_epoch:\n",
    "            print_in_color(LRA.msg, (255, 255, 0), (55, 65, 80))\n",
    "\n",
    "        if self.stop_count > self.stop_patience - 1:\n",
    "            LRA.msg = f' training has been halted at epoch {epoch + 1} after {self.stop_patience} adjustments of learning rate with no improvement'\n",
    "            print_in_color(LRA.msg, (0, 255, 0), (55, 65, 80))\n",
    "            self.model_.stop_training = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66668c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "patience=1\n",
    "stop_patience=4\n",
    "threshold=.9\n",
    "factor=.5\n",
    "dwell=False\n",
    "model_type='VGG19'\n",
    "epochs=15\n",
    "callbacks=[LRA(patience=patience,stop_patience=stop_patience, threshold=threshold,\n",
    "                   factor=factor,dwell=dwell, model_name=model_type, freeze=freeze, end_epoch=epochs - 1 )]\n",
    "\n",
    "history=model.fit(x=train_gen,  epochs=epochs, verbose=1, callbacks=callbacks,  validation_data=valid_gen,\n",
    "               validation_steps=None,  shuffle=False,  initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10739fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = r'G:\\Dataset-image-Eye_Data_New\\Test\\Copy of vgg19_model.h5'\n",
    "try:\n",
    "    model = load_model(model_path)\n",
    "    print(\"Model loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4100b3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_eval_metrics(e_data):\n",
    "    msg = 'Model Metrics after Training'\n",
    "    print_in_color(msg, (255,255,0), (55,65,80))\n",
    "    msg = '{0:^24s}{1:^24s}'.format('Metric', 'Value')\n",
    "    print_in_color(msg, (255,255,0), (55,65,80))\n",
    "    for key, value in e_data.items():\n",
    "        print(f'{key:^24s}{value:^24.5f}')\n",
    "    acc = e_data['accuracy'] * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f2ac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'VGG19' \n",
    "e_dict = model.evaluate(test_gen, batch_size=test_batch_size, verbose=1, steps=test_steps, return_dict=True)\n",
    "acc = display_eval_metrics(e_dict)\n",
    "msg = f'Accuracy on the test set is {acc:5.2f} %'\n",
    "preds = model.predict(test_gen, batch_size=test_batch_size, verbose=0, steps=None)\n",
    "print_in_color(msg, (0,255,0), (55,65,80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b06441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_info(test_gen, preds, print_code, save_dir, subject):\n",
    "    class_dict = test_gen.class_indices\n",
    "    labels = test_gen.labels\n",
    "    file_names = test_gen.filenames\n",
    "    error_list = []\n",
    "    true_class = []\n",
    "    pred_class = []\n",
    "    prob_list = []\n",
    "    new_dict = {}\n",
    "    error_indices = []\n",
    "    y_pred = []\n",
    "\n",
    "    for key, value in class_dict.items():\n",
    "        new_dict[value] = key             \n",
    "\n",
    "    classes = list(new_dict.values())     \n",
    "    dict_as_text = str(new_dict)\n",
    "\n",
    "    dict_name = subject + '-' + model_type + '-' + str(len(classes)) + '.txt'\n",
    "    dict_path = os.path.join(save_dir, dict_name)\n",
    "    with open(dict_path, 'w') as x_file:\n",
    "        x_file.write(dict_as_text)\n",
    "\n",
    "    errors = 0\n",
    "    for i, p in enumerate(preds):\n",
    "        pred_index = np.argmax(p)\n",
    "        true_index = labels[i] \n",
    "        if pred_index != true_index: \n",
    "            error_list.append(file_names[i])\n",
    "            true_class.append(new_dict[true_index])\n",
    "            pred_class.append(new_dict[pred_index])\n",
    "            prob_list.append(p[pred_index])\n",
    "            error_indices.append(true_index)\n",
    "            errors = errors + 1\n",
    "        y_pred.append(pred_index)\n",
    "\n",
    "    if print_code != 0:\n",
    "        if errors > 0:\n",
    "            if print_code > errors:\n",
    "                r = errors\n",
    "            else:\n",
    "                r = print_code\n",
    "            msg = '{0:^28s}{1:^28s}{2:^28s}{3:^16s}'.format('Filename', 'Predicted Class', 'True Class', 'Probability')\n",
    "            print_in_color(msg, (0,255,0), (55,65,80))\n",
    "            for i in range(r):\n",
    "                msg = '{0:^28s}{1:^28s}{2:^28s}{3:4s}{4:^6.4f}'.format(\n",
    "                    error_list[i], pred_class[i], true_class[i], ' ', prob_list[i]\n",
    "                )\n",
    "                print_in_color(msg, (255,255,255), (55,65,60))\n",
    "        else:\n",
    "            msg = 'With accuracy of 100 % there are no errors to print'\n",
    "            print_in_color(msg, (0,255,0), (55,65,80))\n",
    "\n",
    "    if errors > 0:\n",
    "        plot_bar = []\n",
    "        plot_class = []\n",
    "        for key, value in new_dict.items():\n",
    "            count = error_indices.count(key)\n",
    "            if count != 0:\n",
    "                plot_bar.append(count) \n",
    "                plot_class.append(value)   \n",
    "\n",
    "        fig = plt.figure()\n",
    "        fig.set_figheight(len(plot_class) / 3)\n",
    "        fig.set_figwidth(10)\n",
    "        plt.style.use('fivethirtyeight')\n",
    "        for i in range(len(plot_class)):\n",
    "            c = plot_class[i]\n",
    "            x = plot_bar[i]\n",
    "            plt.barh(c, x)\n",
    "            plt.title(' Errors by Class on Test Set')\n",
    "\n",
    "        plt.savefig(f\"Errors_by_Class_{model_type}.png\", bbox_inches='tight')\n",
    "\n",
    "    if len(classes) <= 20:\n",
    "        y_true = np.array(labels)\n",
    "        y_pred = np.array(y_pred)\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        clr = classification_report(y_true, y_pred, target_names=classes)\n",
    "        length = len(classes)\n",
    "\n",
    "        if length < 8:\n",
    "            fig_width = 8\n",
    "            fig_height = 8\n",
    "        else:\n",
    "            fig_width = length\n",
    "            fig_height = length\n",
    "\n",
    "        plt.figure(figsize=(fig_width, fig_height))\n",
    "        sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)\n",
    "        plt.xticks(np.arange(length) + .5, classes, rotation=90)\n",
    "        plt.yticks(np.arange(length) + .5, classes, rotation=0)\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.savefig(f\"confusion_matrix_{model_type}.png\", bbox_inches='tight')\n",
    "        plt.show()\n",
    "        print(\"Classification Report:\\n----------------------\\n\", clr)\n",
    "\n",
    "print_code = 20\n",
    "print_info(test_gen, preds, print_code, save_dir, subject)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
